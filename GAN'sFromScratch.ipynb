{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN'sFromScratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yf9XATeao_Kl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms  as transform\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "batch_size = 64\n",
        "image_size = 64\n",
        "\n",
        "transform = transform.Compose([transform.Scale(image_size), transform.ToTensor(), transform.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
        "dataset = dset.CIFAR10(root = 'content/drive/My Drive/data/cifar-10-batches-py', download = True, transform = transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
        "\n",
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    m.weight.data.normal_(0.0, .02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    m.weight.data.normal_(1.0, .02)\n",
        "    m.bias.data.fill_(0)\n",
        "\n",
        "class G(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(G, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "                nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(True),\n",
        "                nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),\n",
        "                nn.Tanh()\n",
        "    )\n",
        "    \n",
        "  def forward(self, input):\n",
        "    output = self.main(input)\n",
        "    return output\n",
        "    \n",
        "netG = G()\n",
        "netG.apply(weights_init)\n",
        "\n",
        "\n",
        "class D(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(D, self).__init__()\n",
        "    self.main = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
        "                nn.LeakyReLU(.2, inplace = True),\n",
        "                nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.LeakyReLU(.2, inplace = True),\n",
        "                nn.Conv2d(128, 256, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.LeakyReLU(.2, inplace = True),\n",
        "                nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.LeakyReLU(.2, inplace = True),\n",
        "                nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
        "                nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "  def forward(self, input):\n",
        "    output = self.main(input)\n",
        "    return output.view(-1)\n",
        "    \n",
        "netD = D()\n",
        "netD.apply(weights_init)\n",
        "\n",
        "img_list = []\n",
        "img_list1 = []\n",
        "criterion = nn.BCELoss()\n",
        "optimizerG = optim.Adam(netG.parameters(), lr = .0002, betas = (.5, .999))\n",
        "optimizerD = optim.Adam(netD.parameters(), lr = .0002, betas = (.5, .999))\n",
        "\n",
        "\n",
        "for epoch in range(5):\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "    \n",
        "    netD.zero_grad()\n",
        "    real, _ = data\n",
        "    input = Variable(real)\n",
        "    target = Variable(torch.ones(input.size()[0]))\n",
        "    output = netD(input)\n",
        "    errD_real = criterion(output, target)\n",
        "    \n",
        "    noise = Variable(torch.randn(input.size()[0], 100, 1, 1))\n",
        "    fake = netG(noise)\n",
        "    target = Variable(torch.zeros(input.size()[0]))\n",
        "    output = netD(fake.detach())\n",
        "    errD_fake = criterion(output, target)\n",
        "    \n",
        "    errD = errD_real + errD_fake\n",
        "    errD.backward()\n",
        "    optimizerD.step()\n",
        "    \n",
        "    netG.zero_grad()\n",
        "    target = Variable(torch.ones(input.size()[0]))\n",
        "    output = netD(fake)\n",
        "    errG = criterion(output, target)\n",
        "    errG.backward()\n",
        "    optimizerG.step()\n",
        "    \n",
        "    print('[%d/%d][%d/%d] Loss_D : %.4f Loss_G : %.4f' % (epoch, 25, i, len(dataloader), errD.data[0], errG.data[0]))\n",
        "    if i % 100 == 0:\n",
        "      #vutils.save_image(real, '%s/real_samples.pbm' % 'content/drive', normalize = True)\n",
        "      img_list.append(vutils.make_grid(real, padding=2, normalize=True))\n",
        "      fake = netG(noise)\n",
        "      #vutils.save_image(fake, '%s/fake_samples_epoch_%03d.png' % ('content/drive/My Drive/computer science', epoch), normalize = True)\n",
        "      img_list1.append(vutils.make_grid(fake, padding=2, normalize=True))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}